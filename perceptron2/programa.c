#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <string.h>
#include <time.h>
#include <unistd.h>
#include <ctype.h>

#define MAX_EPOCHS 1000
#define MAX_SAMPLES 1000
#define MAX_FEATURES 10
#define MAX_MODELS 10

// EnumeraciÃ³n de algoritmos disponibles
typedef enum {
    ALGO_PERCEPTRON_SIMPLE,
    ALGO_KNN,                 
    ALGO_MLP_BASICO           
} AlgorithmType;

// EnumeraciÃ³n de funciones de activaciÃ³n
typedef enum {
    ACTIVATION_SIGMOIDE,
    ACTIVATION_TANH, 
    ACTIVATION_RELU,
    ACTIVATION_STEP
} ActivationFunction;

// Estructura para el perceptrÃ³n simple
typedef struct {
    double weights[MAX_FEATURES];
    double bias;
    int num_features;
    ActivationFunction activation;
} PerceptronSimple;

// Estructura bÃ¡sica para MLP
typedef struct {
    double weights_layer1[MAX_FEATURES][5];
    double weights_layer2[5];                
    double bias_layer1[5];
    double bias_layer2;
    int num_features;
    int num_hidden;
} MLPBasico;

// Estructura para K-NN
typedef struct {
    double samples[MAX_SAMPLES][MAX_FEATURES];
    int targets[MAX_SAMPLES];
    int num_samples;
    int num_features;
    int k;
} KNNModel;

// Estructura principal del modelo
typedef struct {
    AlgorithmType algorithm;
    char name[50];
    double learning_rate;
    double error_history[MAX_EPOCHS];
    int epochs_trained;
    int num_features;
    
    union {
        PerceptronSimple perceptron;
        MLPBasico mlp_basico;
        KNNModel knn_model;
    } model;
    
    time_t created_at;
    time_t last_trained;
} Model;

// Estructura para datos de entrenamiento
typedef struct {
    double features[MAX_FEATURES];
    int target;
    char label[50];
} TrainingData;

// Prototipos de funciones
void initialize_model(Model *model, AlgorithmType algo, int num_features);
int save_model(const Model *model, const char *filename);
int load_model(Model *model, const char *filename);
void print_model_info(const Model *model);
void train_perceptron_simple(Model *model, TrainingData data[], int num_samples);
void train_mlp_basico(Model *model, TrainingData data[], int num_samples);
void train_knn(Model *model, TrainingData data[], int num_samples);
int predict(const Model *model, const double features[]);
double predict_proba(const Model *model, const double features[]);
double sigmoid(double x);
double tanh_activation(double x);
double relu(double x);
double step_function(double x);
double activation_function(ActivationFunction func, double x);
double activation_derivative(ActivationFunction func, double x);

// Nuevas funciones de visualizaciÃ³n mejoradas
void show_training_dashboard(Model *model, TrainingData data[], int num_samples, 
                           int current_epoch, double current_error);
void plot_error_evolution(const Model *model, int current_epoch);
void show_weights_and_bias(const Model *model);
void show_classification_plane(const Model *model, TrainingData data[], int num_samples);
void show_confidence_map_enhanced(const Model *model, TrainingData data[], int num_samples);
void print_confusion_matrix_enhanced(const Model *model, TrainingData data[], int num_samples);

void show_data_analysis(TrainingData data[], int num_samples, int num_features);
int load_training_data(const char *filename, TrainingData data[], int max_samples);
void clear_screen();
void print_help();
void show_comparison_metrics(Model *models[], int num_models, TrainingData data[], int num_samples);
double calculate_accuracy(const Model *model, TrainingData data[], int num_samples);
void print_confusion_matrix(const Model *model, TrainingData data[], int num_samples);

// Funciones para problemas predefinidos
void generate_and_data(TrainingData data[], int *num_samples);
void generate_or_data(TrainingData data[], int *num_samples);
void generate_xor_data(TrainingData data[], int *num_samples);
void show_problem_menu();

// Funciones para MLP bÃ¡sico
double forward_pass_mlp(const MLPBasico *mlp, const double features[]);
void backpropagate_mlp(MLPBasico *mlp, const double features[], int target, double learning_rate);

// Nueva funciÃ³n: Modo automÃ¡tico de entrenamiento y uso
void automatic_mode(const char *data_filename);

// ============================================================================
// NUEVAS FUNCIONES DE VISUALIZACIÃ“N MEJORADAS
// ============================================================================

void show_training_dashboard(Model *model, TrainingData data[], int num_samples, 
                           int current_epoch, double current_error) {
    clear_screen();
    
    // Encabezado principal
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ§  %-47s â”‚\n", model->name);
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    // InformaciÃ³n de entrenamiento
    int progress = (int)((double)(current_epoch + 1) / MAX_EPOCHS * 30);
    printf("â”‚ Ã‰poca: %4d/%-4d | Error: %.4f | LR: %.2f              â”‚\n", 
           current_epoch + 1, MAX_EPOCHS, current_error, model->learning_rate);
    printf("â”‚ [");
    for(int i = 0; i < 30; i++) {
        if(i < progress) printf("â–ˆ");
        else printf(" ");
    }
    printf("] %3d%% â”‚\n", (int)((double)(current_epoch + 1) / MAX_EPOCHS * 100));
    
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    // EvoluciÃ³n del error
    printf("â”‚ ğŸ“ˆ EVOLUCIÃ“N DEL ERROR                                 â”‚\n");
    plot_error_evolution(model, current_epoch);
    
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    // Pesos y bias (solo para perceptrÃ³n)
    if(model->algorithm == ALGO_PERCEPTRON_SIMPLE) {
        show_weights_and_bias(model);
        printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    }
    
    // Plano de clasificaciÃ³n
    printf("â”‚ ğŸ—ºï¸  PLANO DE CLASIFICACIÃ“N                            â”‚\n");
    show_classification_plane(model, data, num_samples);
    
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    // Matriz de confusiÃ³n
    printf("â”‚ ğŸ“Š MATRIZ DE CONFUSIÃ“N                                â”‚\n");
    print_confusion_matrix_enhanced(model, data, num_samples);
    
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    
    printf("\nPresiona Ctrl+C para detener...\n");
}

void plot_error_evolution(const Model *model, int current_epoch) {
    if(current_epoch < 1) return;
    
    int display_points = 50;
    int start_epoch = (current_epoch > display_points) ? current_epoch - display_points : 0;
    int points_to_show = current_epoch - start_epoch + 1;
    
    // Encontrar el rango de errores para escalar
    double min_error = 1e10, max_error = -1e10;
    for(int i = start_epoch; i <= current_epoch; i++) {
        if(model->error_history[i] < min_error) min_error = model->error_history[i];
        if(model->error_history[i] > max_error) max_error = model->error_history[i];
    }
    
    // Asegurar que haya un rango visible
    if(max_error - min_error < 0.001) {
        min_error -= 0.005;
        max_error += 0.005;
    }
    
    int graph_height = 6;
    
    // Crear grÃ¡fico
    for(int line = graph_height; line >= 0; line--) {
        double level = min_error + (max_error - min_error) * line / graph_height;
        
        if(line == graph_height) {
            printf("â”‚ %6.3f â”¤", max_error);
        } else if(line == 0) {
            printf("â”‚ %6.3f â”¤", min_error);
        } else {
            printf("â”‚       â”¤");
        }
        
        for(int i = 0; i < points_to_show; i++) {
            int epoch = start_epoch + i;
            double error = model->error_history[epoch];
            
            double normalized = (error - min_error) / (max_error - min_error);
            int error_line = (int)(normalized * graph_height);
            
            if(error_line == line) {
                printf("â–ˆ");
            } else if(error_line > line && error_line <= line + 2) {
                printf("â–’");
            } else {
                printf(" ");
            }
        }
        printf(" â”‚\n");
    }
    
    // Eje X
    printf("â”‚        ");
    for(int i = 0; i < points_to_show; i++) {
        if(i == 0 || i == points_to_show - 1) {
            printf("â”¼");
        } else {
            printf("â”€");
        }
    }
    printf("â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚\n");
    
    // Etiquetas del eje X
    printf("â”‚         %-4d", start_epoch);
    for(int i = 0; i < points_to_show - 8; i++) printf(" ");
    printf("%4d       â”‚\n", current_epoch);
}

void show_weights_and_bias(const Model *model) {
    printf("â”‚ âš–ï¸  PESOS Y BIAS (Normalizados)                        â”‚\n");
    
    if(model->algorithm != ALGO_PERCEPTRON_SIMPLE) return;
    
    // Encontrar el valor mÃ¡ximo para normalizar
    double max_abs = 0;
    for(int i = 0; i < model->num_features; i++) {
        double abs_val = fabs(model->model.perceptron.weights[i]);
        if(abs_val > max_abs) max_abs = abs_val;
    }
    double bias_abs = fabs(model->model.perceptron.bias);
    if(bias_abs > max_abs) max_abs = bias_abs;
    
    if(max_abs < 1e-10) max_abs = 1.0; // Evitar divisiÃ³n por cero
    
    int bar_width = 20;
    
    for(int i = 0; i < model->num_features; i++) {
        double weight = model->model.perceptron.weights[i];
        int filled = (int)(fabs(weight) / max_abs * bar_width);
        
        printf("â”‚ w%d: ", i + 1);
        for(int j = 0; j < bar_width; j++) {
            if(j < filled) printf("â–ˆ");
            else printf(".");
        }
        printf(" %6.3f â”‚\n", weight);
    }
    
    // Mostrar bias
    double bias = model->model.perceptron.bias;
    int bias_filled = (int)(fabs(bias) / max_abs * bar_width);
    
    printf("â”‚ Bias:");
    for(int j = 0; j < bar_width; j++) {
        if(j < bias_filled) printf("â–ˆ");
        else printf(".");
    }
    printf(" %6.3f â”‚\n", bias);
}

void show_classification_plane(const Model *model, TrainingData data[], int num_samples) {
    int grid_size = 9; // 0-8 para que quepa en el ancho
    
    printf("â”‚ y     ");
    for(int x = 0; x < grid_size; x++) printf("%d ", x);
    printf("  x â”‚\n");
    
    for(int y = grid_size - 1; y >= 0; y--) {
        printf("â”‚ %1d   ", y);
        
        for(int x = 0; x < grid_size; x++) {
            // Convertir coordenadas de grid a caracterÃ­sticas normalizadas
            double fx = (double)x / (grid_size - 1);
            double fy = (double)y / (grid_size - 1);
            double features[2] = {fx, fy};
            
            // Predecir
            int prediction = predict(model, features);
            double confidence = predict_proba(model, features);
            
            // Buscar si hay un punto de datos en esta posiciÃ³n
            char symbol = ' ';
            int has_data_point = 0;
            
            for(int i = 0; i < num_samples; i++) {
                double dx = fabs(data[i].features[0] - fx);
                double dy = fabs(data[i].features[1] - fy);
                if(dx < 0.1 && dy < 0.1) {
                    has_data_point = 1;
                    symbol = (data[i].target == 0) ? 'O' : 'X';
                    break;
                }
            }
            
            if(!has_data_point) {
                // Mostrar regiÃ³n de clasificaciÃ³n
                if(confidence > 0.7) symbol = (prediction == 1) ? '#' : '.';
                else if(confidence > 0.6) symbol = (prediction == 1) ? '*' : ',';
                else symbol = ' ';
            }
            
            printf("%c ", symbol);
        }
        printf(" â”‚\n");
    }
}

void show_confidence_map_enhanced(const Model *model, TrainingData data[], int num_samples) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ¨ MAPA DE CONFIANZA - VISUALIZACIÃ“N 2D               â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    int grid_size = 12;
    
    printf("â”‚     ");
    for(int x = 0; x < grid_size; x++) printf("%d ", x % 10);
    printf("    â”‚\n");
    
    for(int y = grid_size - 1; y >= 0; y--) {
        printf("â”‚ %2d  ", y);
        
        for(int x = 0; x < grid_size; x++) {
            double fx = (double)x / (grid_size - 1);
            double fy = (double)y / (grid_size - 1);
            double features[2] = {fx, fy};
            
            double confidence = predict_proba(model, features);
            char symbol;
            
            if(confidence < 0.3) symbol = ' ';
            else if(confidence < 0.4) symbol = '.';
            else if(confidence < 0.5) symbol = ':';
            else if(confidence < 0.6) symbol = '-';
            else if(confidence < 0.7) symbol = '=';
            else if(confidence < 0.8) symbol = '+';
            else if(confidence < 0.9) symbol = '*';
            else symbol = '#';
            
            printf("%c ", symbol);
        }
        printf(" â”‚\n");
    }
    
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ” LEYENDA:                                            â”‚\n");
    printf("â”‚    ' '=0%%  '.'=30%%  ':'=40%%  '-'=50%%                 â”‚\n");
    printf("â”‚    '='=60%%  '+'=70%%  '*'=80%%  '#'=90%%+              â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

void print_confusion_matrix_enhanced(const Model *model, TrainingData data[], int num_samples) {
    int true_positive = 0, true_negative = 0, false_positive = 0, false_negative = 0;
    
    for(int i = 0; i < num_samples; i++) {
        int prediction = predict(model, data[i].features);
        int actual = data[i].target;
        
        if(actual == 1 && prediction == 1) true_positive++;
        else if(actual == 0 && prediction == 0) true_negative++;
        else if(actual == 0 && prediction == 1) false_positive++;
        else if(actual == 1 && prediction == 0) false_negative++;
    }
    
    double accuracy = (double)(true_positive + true_negative) / num_samples * 100;
    double precision = (true_positive + false_positive) > 0 ? 
                      (double)true_positive / (true_positive + false_positive) * 100 : 0;
    double recall = (true_positive + false_negative) > 0 ? 
                   (double)true_positive / (true_positive + false_negative) * 100 : 0;
    
    printf("â”‚         Pred 0    Pred 1    â”‚\n");
    printf("â”‚ Real 0:   %2d        %2d      â”‚\n", true_negative, false_positive);
    printf("â”‚ Real 1:   %2d        %2d      â”‚\n", false_negative, true_positive);
    printf("â”‚ PrecisiÃ³n: %.1f%%              â”‚\n", accuracy);
    printf("â”‚ Recall:    %.1f%%              â”‚\n", recall);
}

// ============================================================================
// FUNCIONES ORIGINALES MODIFICADAS
// ============================================================================

void show_data_analysis(TrainingData data[], int num_samples, int num_features) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ“Š ANÃLISIS DE DATOS CARGADOS                         â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    int class_0 = 0, class_1 = 0;
    for(int i = 0; i < num_samples; i++) {
        if(data[i].target == 0) class_0++;
        else class_1++;
    }
    
    printf("â”‚ Muestras totales: %-34d â”‚\n", num_samples);
    printf("â”‚ Clase 0: %-3d (%-5.1f%%)                              â”‚\n", 
           class_0, (double)class_0/num_samples*100);
    printf("â”‚ Clase 1: %-3d (%-5.1f%%)                              â”‚\n", 
           class_1, (double)class_1/num_samples*100);
    
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Primeras muestras:                                      â”‚\n");
    for(int i = 0; i < (num_samples < 3 ? num_samples : 3); i++) {
        printf("â”‚   [%.1f, %.1f] -> %-2d                                â”‚\n", 
               data[i].features[0], data[i].features[1], data[i].target);
    }
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

double calculate_accuracy(const Model *model, TrainingData data[], int num_samples) {
    int correct = 0;
    for(int i = 0; i < num_samples; i++) {
        int prediction = predict(model, data[i].features);
        if(prediction == data[i].target) {
            correct++;
        }
    }
    return (double)correct / num_samples;
}

void print_confusion_matrix(const Model *model, TrainingData data[], int num_samples) {
    print_confusion_matrix_enhanced(model, data, num_samples);
}

void show_comparison_metrics(Model *models[], int num_models, TrainingData data[], int num_samples) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ“Š COMPARACIÃ“N DE MODELOS                             â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Modelo        â”‚ PrecisiÃ³n  â”‚ Ã‰pocas     â”‚ Error Final   â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    for(int i = 0; i < num_models; i++) {
        double accuracy = calculate_accuracy(models[i], data, num_samples);
        double final_error = models[i]->epochs_trained > 0 ? 
                           models[i]->error_history[models[i]->epochs_trained - 1] : 0;
        
        printf("â”‚ %-13s â”‚ %8.1f%%  â”‚ %10d â”‚ %13.4f â”‚\n",
               models[i]->name, accuracy * 100, 
               models[i]->epochs_trained, final_error);
    }
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

// ImplementaciÃ³n de funciones para problemas predefinidos
void generate_and_data(TrainingData data[], int *num_samples) {
    data[0].features[0] = 0.0; data[0].features[1] = 0.0; data[0].target = 0;
    data[1].features[0] = 0.0; data[1].features[1] = 1.0; data[1].target = 0;
    data[2].features[0] = 1.0; data[2].features[1] = 0.0; data[2].target = 0;
    data[3].features[0] = 1.0; data[3].features[1] = 1.0; data[3].target = 1;
    *num_samples = 4;
}

void generate_or_data(TrainingData data[], int *num_samples) {
    data[0].features[0] = 0.0; data[0].features[1] = 0.0; data[0].target = 0;
    data[1].features[0] = 0.0; data[1].features[1] = 1.0; data[1].target = 1;
    data[2].features[0] = 1.0; data[2].features[1] = 0.0; data[2].target = 1;
    data[3].features[0] = 1.0; data[3].features[1] = 1.0; data[3].target = 1;
    *num_samples = 4;
}

void generate_xor_data(TrainingData data[], int *num_samples) {
    data[0].features[0] = 0.0; data[0].features[1] = 0.0; data[0].target = 0;
    data[1].features[0] = 0.0; data[1].features[1] = 1.0; data[1].target = 1;
    data[2].features[0] = 1.0; data[2].features[1] = 0.0; data[2].target = 1;
    data[3].features[0] = 1.0; data[3].features[1] = 1.0; data[3].target = 0;
    *num_samples = 4;
}

void show_problem_menu() {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ¯ PROBLEMAS PREDEFINIDOS                             â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ 1. AND (Y LÃ³gico) - ClasificaciÃ³n linealmente separable â”‚\n");
    printf("â”‚ 2. OR (O LÃ³gico) - ClasificaciÃ³n linealmente separable  â”‚\n");
    printf("â”‚ 3. XOR (O Exclusivo) - ClasificaciÃ³n no lineal          â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Ejemplos de uso:                                        â”‚\n");
    printf("â”‚   ./programa --entrenar --problema AND --modelo and.bin â”‚\n");
    printf("â”‚   ./programa --entrenar --problema OR --algoritmo perceptron â”‚\n");
    printf("â”‚   ./programa --entrenar --problema XOR --algoritmo mlp  â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

// ImplementaciÃ³n de funciones de gestiÃ³n de modelos
void initialize_model(Model *model, AlgorithmType algo, int num_features) {
    model->algorithm = algo;
    model->num_features = num_features;
    model->learning_rate = 0.1;
    model->epochs_trained = 0;
    model->created_at = time(NULL);
    model->last_trained = time(NULL);
    
    switch(algo) {
        case ALGO_PERCEPTRON_SIMPLE:
            strcpy(model->name, "PerceptrÃ³n Simple");
            for(int i = 0; i < num_features; i++) {
                model->model.perceptron.weights[i] = ((double)rand() / RAND_MAX) * 2 - 1;
            }
            model->model.perceptron.bias = ((double)rand() / RAND_MAX) * 2 - 1;
            model->model.perceptron.num_features = num_features;
            model->model.perceptron.activation = ACTIVATION_SIGMOIDE;
            break;
            
        case ALGO_MLP_BASICO:
            strcpy(model->name, "MLP BÃ¡sico (2 capas)");
            model->model.mlp_basico.num_features = num_features;
            model->model.mlp_basico.num_hidden = 5;
            
            // Inicializar pesos capa entrada->oculta
            for(int i = 0; i < num_features; i++) {
                for(int j = 0; j < 5; j++) {
                    model->model.mlp_basico.weights_layer1[i][j] = ((double)rand() / RAND_MAX) * 2 - 1;
                }
            }
            
            // Inicializar pesos capa oculta->salida
            for(int j = 0; j < 5; j++) {
                model->model.mlp_basico.weights_layer2[j] = ((double)rand() / RAND_MAX) * 2 - 1;
            }
            
            // Inicializar biases
            for(int j = 0; j < 5; j++) {
                model->model.mlp_basico.bias_layer1[j] = ((double)rand() / RAND_MAX) * 2 - 1;
            }
            model->model.mlp_basico.bias_layer2 = ((double)rand() / RAND_MAX) * 2 - 1;
            break;
            
        case ALGO_KNN:
            strcpy(model->name, "K-Vecinos MÃ¡s Cercanos");
            model->model.knn_model.k = 3;
            model->model.knn_model.num_samples = 0;
            model->model.knn_model.num_features = num_features;
            break;
    }
    
    for(int i = 0; i < MAX_EPOCHS; i++) {
        model->error_history[i] = 0.0;
    }
}

int save_model(const Model *model, const char *filename) {
    FILE *file = fopen(filename, "wb");
    if(!file) return 0;
    
    int result = fwrite(model, sizeof(Model), 1, file);
    fclose(file);
    
    return result == 1;
}

int load_model(Model *model, const char *filename) {
    FILE *file = fopen(filename, "rb");
    if(!file) return 0;
    
    int result = fread(model, sizeof(Model), 1, file);
    fclose(file);
    
    return result == 1;
}

void print_model_info(const Model *model) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ¤– INFORMACIÃ“N DEL MODELO                             â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Nombre: %-45s â”‚\n", model->name);
    printf("â”‚ Algoritmo: ");
    switch(model->algorithm) {
        case ALGO_PERCEPTRON_SIMPLE: printf("PerceptrÃ³n Simple%-29s â”‚\n", ""); break;
        case ALGO_MLP_BASICO: printf("MLP BÃ¡sico (2 capas)%-26s â”‚\n", ""); break;
        case ALGO_KNN: printf("K-Vecinos MÃ¡s Cercanos%-24s â”‚\n", ""); break;
    }
    printf("â”‚ CaracterÃ­sticas: %-36d â”‚\n", model->num_features);
    printf("â”‚ Ã‰pocas entrenadas: %-34d â”‚\n", model->epochs_trained);
    printf("â”‚ Tasa aprendizaje: %-35.3f â”‚\n", model->learning_rate);
    
    char time_buf[26];
    struct tm* tm_info = localtime(&model->created_at);
    strftime(time_buf, 26, "%Y-%m-%d %H:%M:%S", tm_info);
    printf("â”‚ Creado: %-42s â”‚\n", time_buf);
    
    tm_info = localtime(&model->last_trained);
    strftime(time_buf, 26, "%Y-%m-%d %H:%M:%S", tm_info);
    printf("â”‚ Ãšltimo entrenamiento: %-31s â”‚\n", time_buf);
    
    if(model->epochs_trained > 0) {
        printf("â”‚ Error final: %-38.4f â”‚\n", model->error_history[model->epochs_trained - 1]);
    }
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

// ImplementaciÃ³n de algoritmos de ML
void train_perceptron_simple(Model *model, TrainingData data[], int num_samples) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ§  ENTRENANDO PERCEPTRÃ“N SIMPLE                       â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ â„¹ï¸  Funciona bien para problemas linealmente separables â”‚\n");
    printf("â”‚    (AND, OR)                                           â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    int convergence = 0;
    for(int epoch = 0; epoch < MAX_EPOCHS && !convergence; epoch++) {
        double total_error = 0.0;
        convergence = 1;
        
        for(int i = 0; i < num_samples; i++) {
            double z = model->model.perceptron.bias;
            for(int j = 0; j < model->num_features; j++) {
                z += model->model.perceptron.weights[j] * data[i].features[j];
            }
            
            double prediction = activation_function(model->model.perceptron.activation, z);
            double error = data[i].target - prediction;
            
            if(fabs(error) > 0.1) {
                convergence = 0;
                
                double delta = model->learning_rate * error * 
                              activation_derivative(model->model.perceptron.activation, z);
                
                model->model.perceptron.bias += delta;
                for(int j = 0; j < model->num_features; j++) {
                    model->model.perceptron.weights[j] += delta * data[i].features[j];
                }
            }
            
            total_error += error * error;
        }
        
        total_error /= num_samples;
        model->error_history[epoch] = total_error;
        model->epochs_trained = epoch + 1;
        
        if(epoch % 10 == 0 || epoch == MAX_EPOCHS - 1 || convergence) {
            show_training_dashboard(model, data, num_samples, epoch, total_error);
            usleep(200000);
        }
        
        if(total_error < 0.01) {
            convergence = 1;
        }
    }
    
    model->last_trained = time(NULL);
    
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ âš ï¸  ENTRENAMIENTO COMPLETADO                           â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ %-55s â”‚\n", 
           convergence ? "ğŸ‰ Convergencia alcanzada" : "ğŸ›‘ LÃ­mite de Ã©pocas alcanzado");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

// ImplementaciÃ³n REAL de MLP bÃ¡sico
void train_mlp_basico(Model *model, TrainingData data[], int num_samples) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ•¸ï¸  ENTRENANDO MLP BÃSICO (2 CAPAS)                   â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ â„¹ï¸  Puede resolver problemas no lineales como XOR       â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    for(int epoch = 0; epoch < MAX_EPOCHS; epoch++) {
        double total_error = 0.0;
        
        for(int i = 0; i < num_samples; i++) {
            // Forward pass
            double output = forward_pass_mlp(&model->model.mlp_basico, data[i].features);
            double error = data[i].target - output;
            
            // Backpropagation
            backpropagate_mlp(&model->model.mlp_basico, data[i].features, data[i].target, model->learning_rate);
            
            total_error += error * error;
        }
        
        total_error /= num_samples;
        model->error_history[epoch] = total_error;
        model->epochs_trained = epoch + 1;
        
        if(epoch % 10 == 0 || epoch == MAX_EPOCHS - 1) {
            show_training_dashboard(model, data, num_samples, epoch, total_error);
            usleep(200000);
        }
        
        if(total_error < 0.01) break;
    }
    
    model->last_trained = time(NULL);
    
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ âš ï¸  ENTRENAMIENTO COMPLETADO                           â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ %-55s â”‚\n", "ğŸ”„ Proceso finalizado");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

void train_knn(Model *model, TrainingData data[], int num_samples) {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ“ ENTRENANDO K-VECINOS MÃS CERCANOS                  â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ â„¹ï¸  Almacena los datos y los usa para clasificaciÃ³n    â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    model->model.knn_model.num_samples = num_samples;
    for(int i = 0; i < num_samples; i++) {
        for(int j = 0; j < model->num_features; j++) {
            model->model.knn_model.samples[i][j] = data[i].features[j];
        }
        model->model.knn_model.targets[i] = data[i].target;
    }
    model->epochs_trained = 1;
    model->last_trained = time(NULL);
}

// Funciones de MLP bÃ¡sico
double forward_pass_mlp(const MLPBasico *mlp, const double features[]) {
    double hidden[5];
    
    // Capa entrada -> oculta
    for(int j = 0; j < mlp->num_hidden; j++) {
        hidden[j] = mlp->bias_layer1[j];
        for(int i = 0; i < mlp->num_features; i++) {
            hidden[j] += mlp->weights_layer1[i][j] * features[i];
        }
        hidden[j] = sigmoid(hidden[j]);
    }
    
    // Capa oculta -> salida
    double output = mlp->bias_layer2;
    for(int j = 0; j < mlp->num_hidden; j++) {
        output += mlp->weights_layer2[j] * hidden[j];
    }
    
    return sigmoid(output);
}

void backpropagate_mlp(MLPBasico *mlp, const double features[], int target, double learning_rate) {
    double hidden[5];
    double hidden_activation[5];
    
    // Forward pass
    for(int j = 0; j < mlp->num_hidden; j++) {
        hidden[j] = mlp->bias_layer1[j];
        for(int i = 0; i < mlp->num_features; i++) {
            hidden[j] += mlp->weights_layer1[i][j] * features[i];
        }
        hidden_activation[j] = sigmoid(hidden[j]);
    }
    
    double output = mlp->bias_layer2;
    for(int j = 0; j < mlp->num_hidden; j++) {
        output += mlp->weights_layer2[j] * hidden_activation[j];
    }
    double output_activation = sigmoid(output);
    
    // Backward pass
    double output_error = target - output_activation;
    double output_delta = output_error * output_activation * (1 - output_activation);
    
    // Actualizar pesos capa salida
    mlp->bias_layer2 += learning_rate * output_delta;
    for(int j = 0; j < mlp->num_hidden; j++) {
        mlp->weights_layer2[j] += learning_rate * output_delta * hidden_activation[j];
    }
    
    // Backpropagate a capa oculta
    for(int j = 0; j < mlp->num_hidden; j++) {
        double hidden_error = output_delta * mlp->weights_layer2[j];
        double hidden_delta = hidden_error * hidden_activation[j] * (1 - hidden_activation[j]);
        
        // Actualizar pesos capa oculta
        mlp->bias_layer1[j] += learning_rate * hidden_delta;
        for(int i = 0; i < mlp->num_features; i++) {
            mlp->weights_layer1[i][j] += learning_rate * hidden_delta * features[i];
        }
    }
}

// Funciones de predicciÃ³n
int predict(const Model *model, const double features[]) {
    switch(model->algorithm) {
        case ALGO_PERCEPTRON_SIMPLE: {
            double z = model->model.perceptron.bias;
            for(int i = 0; i < model->num_features; i++) {
                z += model->model.perceptron.weights[i] * features[i];
            }
            double prediction = activation_function(model->model.perceptron.activation, z);
            return prediction > 0.5 ? 1 : 0;
        }
        
        case ALGO_MLP_BASICO: {
            double prediction = forward_pass_mlp(&model->model.mlp_basico, features);
            return prediction > 0.5 ? 1 : 0;
        }
        
        case ALGO_KNN: {
            if(model->model.knn_model.num_samples == 0) return 0;
            
            double distances[MAX_SAMPLES];
            for(int i = 0; i < model->model.knn_model.num_samples; i++) {
                double distance = 0;
                for(int j = 0; j < model->num_features; j++) {
                    double diff = features[j] - model->model.knn_model.samples[i][j];
                    distance += diff * diff;
                }
                distances[i] = sqrt(distance);
            }
            
            int class0 = 0, class1 = 0;
            int k = model->model.knn_model.k;
            if(k > model->model.knn_model.num_samples) {
                k = model->model.knn_model.num_samples;
            }
            
            for(int n = 0; n < k; n++) {
                int min_idx = -1;
                double min_dist = 1e10;
                for(int i = 0; i < model->model.knn_model.num_samples; i++) {
                    if(distances[i] < min_dist) {
                        min_dist = distances[i];
                        min_idx = i;
                    }
                }
                
                if(min_idx != -1) {
                    if(model->model.knn_model.targets[min_idx] == 0) class0++;
                    else class1++;
                    distances[min_idx] = 1e10;
                }
            }
            
            return class1 > class0 ? 1 : 0;
        }
        
        default:
            return 0;
    }
}

double predict_proba(const Model *model, const double features[]) {
    switch(model->algorithm) {
        case ALGO_PERCEPTRON_SIMPLE: {
            double z = model->model.perceptron.bias;
            for(int i = 0; i < model->num_features; i++) {
                z += model->model.perceptron.weights[i] * features[i];
            }
            return sigmoid(z);
        }
        
        case ALGO_MLP_BASICO: {
            return forward_pass_mlp(&model->model.mlp_basico, features);
        }
        
        case ALGO_KNN: {
            if(model->model.knn_model.num_samples == 0) return 0.0;
            
            double distances[MAX_SAMPLES];
            for(int i = 0; i < model->model.knn_model.num_samples; i++) {
                double distance = 0;
                for(int j = 0; j < model->num_features; j++) {
                    double diff = features[j] - model->model.knn_model.samples[i][j];
                    distance += diff * diff;
                }
                distances[i] = sqrt(distance);
            }
            
            int class1_count = 0;
            int k = model->model.knn_model.k;
            if(k > model->model.knn_model.num_samples) {
                k = model->model.knn_model.num_samples;
            }
            
            for(int n = 0; n < k; n++) {
                int min_idx = -1;
                double min_dist = 1e10;
                for(int i = 0; i < model->model.knn_model.num_samples; i++) {
                    if(distances[i] < min_dist) {
                        min_dist = distances[i];
                        min_idx = i;
                    }
                }
                
                if(min_idx != -1) {
                    if(model->model.knn_model.targets[min_idx] == 1) class1_count++;
                    distances[min_idx] = 1e10;
                }
            }
            
            return (double)class1_count / k;
        }
        
        default:
            return predict(model, features) ? 1.0 : 0.0;
    }
}

// Funciones de activaciÃ³n
double sigmoid(double x) {
    return 1.0 / (1.0 + exp(-x));
}

double tanh_activation(double x) {
    return tanh(x);
}

double relu(double x) {
    return x > 0 ? x : 0;
}

double step_function(double x) {
    return x >= 0 ? 1.0 : 0.0;
}

double activation_function(ActivationFunction func, double x) {
    switch(func) {
        case ACTIVATION_SIGMOIDE: return sigmoid(x);
        case ACTIVATION_TANH: return tanh_activation(x);
        case ACTIVATION_RELU: return relu(x);
        case ACTIVATION_STEP: return step_function(x);
        default: return sigmoid(x);
    }
}

double activation_derivative(ActivationFunction func, double x) {
    switch(func) {
        case ACTIVATION_SIGMOIDE: {
            double s = sigmoid(x);
            return s * (1 - s);
        }
        case ACTIVATION_TANH: {
            double t = tanh(x);
            return 1 - t * t;
        }
        case ACTIVATION_RELU: return x > 0 ? 1.0 : 0.0;
        case ACTIVATION_STEP: return 0.0;
        default: {
            double s = sigmoid(x);
            return s * (1 - s);
        }
    }
}

// Funciones auxiliares
int load_training_data(const char *filename, TrainingData data[], int max_samples) {
    FILE *file = fopen(filename, "r");
    if(!file) return 0;
    
    char line[256];
    int count = 0;
    
    while(fgets(line, sizeof(line), file) && count < max_samples) {
        if(line[0] == '#' || line[0] == '\n' || line[0] == '\r') continue;
        
        double x1, x2;
        int target;
        if(sscanf(line, "%lf %lf %d", &x1, &x2, &target) == 3) {
            data[count].features[0] = x1;
            data[count].features[1] = x2;
            data[count].target = target;
            sprintf(data[count].label, "Clase %d", target);
            count++;
        }
    }
    
    fclose(file);
    return count;
}

void clear_screen() {
    printf("\033[2J\033[1;1H");
}

void print_help() {
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ¯ SISTEMA DE MACHINE LEARNING - AYUDA                â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ âš ï¸  ALGORITMOS IMPLEMENTADOS:                         â”‚\n");
    printf("â”‚   - PerceptrÃ³n Simple: Problemas LINEALES (AND, OR)    â”‚\n");
    printf("â”‚   - MLP BÃ¡sico: Problemas NO LINEALES (XOR)            â”‚\n");
    printf("â”‚   - K-Vecinos: Algoritmo basado en instancias          â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ”¥ MODO AUTOMÃTICO (NUEVO):                           â”‚\n");
    printf("â”‚   ./programa datos.txt                                 â”‚\n");
    printf("â”‚   - Carga y entrena automÃ¡ticamente                    â”‚\n");
    printf("â”‚   - Selecciona el mejor algoritmo                      â”‚\n");
    printf("â”‚   - Permite predicciones interactivas                  â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ§  ENTRENAR modelo:                                   â”‚\n");
    printf("â”‚   ./programa --entrenar --problema AND|OR|XOR          â”‚\n");
    printf("â”‚   ./programa --entrenar datos.txt                      â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ¯ USAR modelo:                                       â”‚\n");
    printf("â”‚   ./programa --usar modelo.bin [datos.txt]             â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ¨ VISUALIZAR modelo:                                 â”‚\n");
    printf("â”‚   ./programa --visualizar modelo.bin [datos.txt]       â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ“Š COMPARAR modelos:                                  â”‚\n");
    printf("â”‚   ./programa --comparar modelo1.bin modelo2.bin ...    â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ ğŸ“š PROBLEMAS PREDEFINIDOS:                            â”‚\n");
    printf("â”‚   ./programa --problemas                               â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Ejemplos prÃ¡cticos:                                    â”‚\n");
    printf("â”‚   ./programa mis_datos.txt                             â”‚\n");
    printf("â”‚   ./programa --entrenar --problema XOR --algoritmo mlp â”‚\n");
    printf("â”‚   ./programa --usar modelo.bin                         â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

// NUEVA FUNCIÃ“N: Modo automÃ¡tico que entrena y usa el modelo
void automatic_mode(const char *data_filename) {
    TrainingData data[MAX_SAMPLES];
    int num_samples = load_training_data(data_filename, data, MAX_SAMPLES);
    
    if(num_samples == 0) {
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ âŒ ERROR CARGANDO DATOS                               â”‚\n");
        printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
        printf("â”‚ No se pudo cargar: %-35s â”‚\n", data_filename);
        printf("â”‚ Formato esperado: x1 x2 target                         â”‚\n");
        printf("â”‚ Ejemplo:                                               â”‚\n");
        printf("â”‚   0.0 0.0 0                                            â”‚\n");
        printf("â”‚   0.0 1.0 1                                            â”‚\n");
        printf("â”‚   1.0 0.0 1                                            â”‚\n");
        printf("â”‚   1.0 1.0 0                                            â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
        return;
    }
    
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ âœ… DATOS CARGADOS EXITOSAMENTE                         â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Muestras: %-45d â”‚\n", num_samples);
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    // Mostrar anÃ¡lisis de datos
    show_data_analysis(data, num_samples, 2);
    
    // Seleccionar algoritmo automÃ¡ticamente basado en los datos
    AlgorithmType algo;
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ” ANALIZANDO DATOS                                    â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    
    // Detectar si es un problema lineal o no lineal
    int is_linear = 1;
    for(int i = 0; i < num_samples && is_linear; i++) {
        for(int j = i + 1; j < num_samples && is_linear; j++) {
            if(data[i].target != data[j].target) {
                double dx = data[i].features[0] - data[j].features[0];
                double dy = data[i].features[1] - data[j].features[1];
                if(fabs(dx) > 0.5 && fabs(dy) > 0.5) {
                    is_linear = 0;
                }
            }
        }
    }
    
    if(is_linear) {
        algo = ALGO_PERCEPTRON_SIMPLE;
        printf("â”‚ âœ… Problema lineal detectado                          â”‚\n");
        printf("â”‚ ğŸ¯ Usando PerceptrÃ³n Simple                          â”‚\n");
    } else {
        algo = ALGO_MLP_BASICO;
        printf("â”‚ âœ… Problema no lineal detectado                       â”‚\n");
        printf("â”‚ ğŸ¯ Usando MLP BÃ¡sico                                 â”‚\n");
    }
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    
    // Entrenar el modelo
    Model model;
    initialize_model(&model, algo, 2);
    
    printf("\n");
    print_model_info(&model);
    
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸš€ INICIANDO ENTRENAMIENTO                            â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    switch(algo) {
        case ALGO_PERCEPTRON_SIMPLE:
            train_perceptron_simple(&model, data, num_samples);
            break;
        case ALGO_MLP_BASICO:
            train_mlp_basico(&model, data, num_samples);
            break;
        case ALGO_KNN:
            train_knn(&model, data, num_samples);
            break;
    }
    
    // Mostrar resultados del entrenamiento
    double accuracy = calculate_accuracy(&model, data, num_samples);
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ¯ RESULTADOS FINALES                                 â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ PrecisiÃ³n: %-43.1f%% â”‚\n", accuracy * 100);
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    
    // Guardar el modelo automÃ¡ticamente
    char model_filename[100];
    snprintf(model_filename, sizeof(model_filename), "modelo_automatico_%ld.bin", time(NULL));
    if(save_model(&model, model_filename)) {
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ’¾ MODELO GUARDADO                                    â”‚\n");
        printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
        printf("â”‚ Archivo: %-45s â”‚\n", model_filename);
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    }
    
    // Modo interactivo para hacer predicciones
    printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ ğŸ® MODO INTERACTIVO DE PREDICCIONES                   â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Ingrese datos (x1 x2) o 'fin' para terminar             â”‚\n");
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
    
    char input[100];
    while(1) {
        printf("ğŸ“¥ Ingrese datos para predecir: ");
        if(fgets(input, sizeof(input), stdin) == NULL) break;
        
        if(strncmp(input, "fin", 3) == 0) break;
        
        double x1, x2;
        if(sscanf(input, "%lf %lf", &x1, &x2) == 2) {
            double features[2] = {x1, x2};
            int prediction = predict(&model, features);
            double confidence = predict_proba(&model, features);
            
            printf("   ğŸ“Š PredicciÃ³n: %d (Confianza: %.1f%%)\n", 
                   prediction, confidence * 100);
            
            // Mostrar interpretaciÃ³n
            if(prediction == 0) {
                printf("   ğŸ” InterpretaciÃ³n: Clase 0");
            } else {
                printf("   ğŸ” InterpretaciÃ³n: Clase 1");
            }
            
            if(confidence > 0.8) {
                printf(" - âœ… Alta confianza\n");
            } else if(confidence > 0.6) {
                printf(" - âš ï¸  Confianza media\n");
            } else {
                printf(" - â— Baja confianza\n");
            }
        } else {
            printf("âŒ Formato incorrecto. Use: x1 x2\n");
        }
    }
    
    printf("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
    printf("â”‚ âœ… PROGRAMA TERMINADO                                  â”‚\n");
    printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
    printf("â”‚ Modelo guardado en: %-35s â”‚\n", model_filename);
    printf("â”‚ Reutilizar con: ./programa --usar %-19s â”‚\n", model_filename);
    printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
}

int main(int argc, char *argv[]) {
    srand(time(NULL));
    
    if(argc < 2) {
        print_help();
        return 1;
    }

    // MODO AUTOMÃTICO: Si el argumento es un archivo de datos
    if(argv[1][0] != '-') {
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ¤– MODO AUTOMÃTICO ACTIVADO                           â”‚\n");
        printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
        printf("â”‚ Archivo de datos: %-35s â”‚\n", argv[1]);
        printf("â”‚ Entrenamiento automÃ¡tico iniciado                      â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        automatic_mode(argv[1]);
        return 0;
    }
    
    // Modos de operaciÃ³n con flags
    if(strcmp(argv[1], "--entrenar") == 0) {
        TrainingData data[MAX_SAMPLES];
        int num_samples = 0;
        char model_filename[100] = "modelo.bin";
        AlgorithmType algo = ALGO_PERCEPTRON_SIMPLE;
        int use_predefined = 0;
        
        // Procesar argumentos
        for(int i = 2; i < argc; i++) {
            if(strcmp(argv[i], "--algoritmo") == 0 && i+1 < argc) {
                i++;
                if(strcmp(argv[i], "perceptron") == 0) algo = ALGO_PERCEPTRON_SIMPLE;
                else if(strcmp(argv[i], "mlp") == 0) algo = ALGO_MLP_BASICO;
                else if(strcmp(argv[i], "knn") == 0) algo = ALGO_KNN;
            }
            else if(strcmp(argv[i], "--problema") == 0 && i+1 < argc) {
                i++;
                use_predefined = 1;
                if(strcmp(argv[i], "AND") == 0) generate_and_data(data, &num_samples);
                else if(strcmp(argv[i], "OR") == 0) generate_or_data(data, &num_samples);
                else if(strcmp(argv[i], "XOR") == 0) generate_xor_data(data, &num_samples);
                else {
                    printf("âŒ Problema desconocido. Usando XOR por defecto.\n");
                    generate_xor_data(data, &num_samples);
                }
            }
            else if(strcmp(argv[i], "--modelo") == 0 && i+1 < argc) {
                i++;
                strcpy(model_filename, argv[i]);
            }
            else {
                // Asumir que es archivo de datos
                num_samples = load_training_data(argv[i], data, MAX_SAMPLES);
                if(num_samples == 0) {
                    printf("âŒ No se pudo cargar %s\n", argv[i]);
                    return 1;
                }
            }
        }
        
        // Si no se especificÃ³ problema ni archivo, mostrar menÃº
        if(num_samples == 0 && !use_predefined) {
            show_problem_menu();
            return 1;
        }
        
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ¯ ENTRENAMIENTO DE MODELO                           â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        Model model;
        initialize_model(&model, algo, 2);
        
        show_data_analysis(data, num_samples, 2);
        printf("\n");
        print_model_info(&model);
        
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸš€ INICIANDO ENTRENAMIENTO                            â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        // Entrenar segÃºn el algoritmo seleccionado
        switch(algo) {
            case ALGO_PERCEPTRON_SIMPLE:
                train_perceptron_simple(&model, data, num_samples);
                break;
            case ALGO_MLP_BASICO:
                train_mlp_basico(&model, data, num_samples);
                break;
            case ALGO_KNN:
                train_knn(&model, data, num_samples);
                break;
        }
        
        // Guardar modelo entrenado
        if(save_model(&model, model_filename)) {
            printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
            printf("â”‚ ğŸ’¾ MODELO GUARDADO                                    â”‚\n");
            printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
            printf("â”‚ Archivo: %-45s â”‚\n", model_filename);
            printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
            
            // Mostrar evaluaciÃ³n final
            double accuracy = calculate_accuracy(&model, data, num_samples);
            printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
            printf("â”‚ ğŸ“Š EVALUACIÃ“N FINAL                                   â”‚\n");
            printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
            printf("â”‚ PrecisiÃ³n: %-43.1f%% â”‚\n", accuracy * 100);
            printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
            
            print_confusion_matrix(&model, data, num_samples);
        } else {
            printf("âŒ Error guardando el modelo\n");
        }
        
    } else if(strcmp(argv[1], "--usar") == 0 && argc >= 3) {
        char model_filename[100] = "modelo.bin";
        char data_filename[100] = "";
        
        // Procesar argumentos
        for(int i = 2; i < argc; i++) {
            if(strcmp(argv[i], "--modelo") == 0 && i+1 < argc) {
                i++;
                strcpy(model_filename, argv[i]);
            } else {
                strcpy(data_filename, argv[i]);
            }
        }
        
        Model model;
        if(!load_model(&model, model_filename)) {
            printf("âŒ Error cargando modelo %s\n", model_filename);
            return 1;
        }
        
        TrainingData new_data[MAX_SAMPLES];
        int num_samples = 0;
        
        if(strlen(data_filename) > 0) {
            num_samples = load_training_data(data_filename, new_data, MAX_SAMPLES);
        } else {
            // Si no hay archivo de datos, usar entrada manual
            printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
            printf("â”‚ ğŸ“ ENTRADA MANUAL DE DATOS                           â”‚\n");
            printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n");
            printf("â”‚ Formato: x1 x2                                        â”‚\n");
            printf("â”‚ Ejemplo: 0 0 para clase 0, 1 1 para clase 1           â”‚\n");
            printf("â”‚ Escriba 'fin' para terminar                           â”‚\n");
            printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
            
            char input[100];
            while(num_samples < MAX_SAMPLES) {
                printf("ğŸ“¥ Datos %d: ", num_samples + 1);
                if(fgets(input, sizeof(input), stdin) == NULL) break;
                
                if(strncmp(input, "fin", 3) == 0) break;
                
                double x1, x2;
                if(sscanf(input, "%lf %lf", &x1, &x2) == 2) {
                    new_data[num_samples].features[0] = x1;
                    new_data[num_samples].features[1] = x2;
                    new_data[num_samples].target = -1; // Desconocido para predicciÃ³n
                    num_samples++;
                } else {
                    printf("âŒ Formato incorrecto. Use: x1 x2\n");
                }
            }
        }
        
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ¯ USANDO MODELO ENTRENADO                           â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        print_model_info(&model);
        
        // Realizar predicciones
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ“Š PREDICCIONES                                       â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
        
        for(int i = 0; i < num_samples; i++) {
            int prediction = predict(&model, new_data[i].features);
            double confidence = predict_proba(&model, new_data[i].features);
            
            printf("   Muestra %d: [%.1f, %.1f] â†’ ", i+1, 
                   new_data[i].features[0], new_data[i].features[1]);
            printf("PredicciÃ³n: %d", prediction);
            printf(" (Confianza: %.1f%%)", confidence * 100);
            
            if(new_data[i].target != -1) {
                if(prediction == new_data[i].target) {
                    printf(" âœ…");
                } else {
                    printf(" âŒ");
                }
            }
            printf("\n");
        }
        
    } else if(strcmp(argv[1], "--visualizar") == 0) {
        char model_filename[100] = "modelo.bin";
        char data_filename[100] = "";
        
        // Procesar argumentos
        for(int i = 2; i < argc; i++) {
            if(strcmp(argv[i], "--modelo") == 0 && i+1 < argc) {
                i++;
                strcpy(model_filename, argv[i]);
            } else {
                strcpy(data_filename, argv[i]);
            }
        }
        
        Model model;
        if(!load_model(&model, model_filename)) {
            printf("âŒ Error cargando modelo %s\n", model_filename);
            return 1;
        }
        
        TrainingData data[MAX_SAMPLES];
        int num_samples = 0;
        
        if(strlen(data_filename) > 0) {
            num_samples = load_training_data(data_filename, data, MAX_SAMPLES);
        } else {
            // Generar datos del problema XOR para visualizaciÃ³n
            generate_xor_data(data, &num_samples);
        }
        
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ¨ VISUALIZACIÃ“N AVANZADA                            â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        print_model_info(&model);
        printf("\n");
        show_confidence_map_enhanced(&model, data, num_samples);
        printf("\n");
        print_confusion_matrix(&model, data, num_samples);
        
    } else if(strcmp(argv[1], "--comparar") == 0 && argc >= 3) {
        // Modo comparaciÃ³n
        printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n");
        printf("â”‚ ğŸ“Š COMPARACIÃ“N DE MODELOS                             â”‚\n");
        printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n");
        
        Model *models[MAX_MODELS];
        int num_models = argc - 2;
        
        if(num_models > MAX_MODELS) {
            printf("âŒ Demasiados modelos (mÃ¡ximo %d)\n", MAX_MODELS);
            return 1;
        }
        
        // Cargar modelos
        for(int i = 0; i < num_models; i++) {
            models[i] = malloc(sizeof(Model));
            if(!load_model(models[i], argv[2 + i])) {
                printf("âŒ Error cargando modelo: %s\n", argv[2 + i]);
                return 1;
            }
        }
        
        // Cargar datos de prueba si se proporcionan
        TrainingData test_data[MAX_SAMPLES];
        int num_test_samples = 0;
        
        if(argc >= 3 + num_models) {
            num_test_samples = load_training_data(argv[2 + num_models], test_data, MAX_SAMPLES);
        }
        
        if(num_test_samples > 0) {
            show_comparison_metrics(models, num_models, test_data, num_test_samples);
        } else {
            printf("â„¹ï¸  Proporciona archivo de datos para comparar mÃ©tricas\n");
        }
        
        // Liberar memoria
        for(int i = 0; i < num_models; i++) {
            free(models[i]);
        }
        
    } else if(strcmp(argv[1], "--problemas") == 0) {
        show_problem_menu();
        
    } else {
        print_help();
    }
    
    return 0;
}
